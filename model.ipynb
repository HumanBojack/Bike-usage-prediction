{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.base import BaseEstimator,TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # => Might want to use cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"count\", \"registered\", \"casual\", \"season\", \"holiday\", \"workingday\"], axis=1) # , \"temp\", \"atemp\"\n",
    "y = df[\"count\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# class DateParser(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "#         X = pd.to_datetime(X[\"datetime\"])\n",
    "#         return_X = pd.DataFrame(\n",
    "#             {\n",
    "#                 \"weekday\": X.dt.weekday,\n",
    "#                 \"hour\": X.dt.hour,\n",
    "#                 \"month\": X.dt.month,\n",
    "#                 \"year\": X.dt.year,\n",
    "#             }\n",
    "#         )\n",
    "#         return return_X\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model_api.app.custom_transformers import DateParser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (DateParser(), [\"datetime\"]),\n",
    "    # (OneHotEncoder(), [\"season\"]),\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return mae, np.sqrt(mse), r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('dateparser', DateParser(),\n",
       "                                                  ['datetime'])])),\n",
       "                ('model', LGBMRegressor())])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([(\"preprocessor\", preprocessor), (\"model\", LGBMRegressor())])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 25.892471238736977\n",
      "RMSE: 41.242403747010655\n",
      "R2: 0.9484673199055353\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mae, rmse, r2 = eval_metrics(y_test, y_pred)\n",
    "print(f\"MAE: {mae}\\nRMSE: {rmse}\\nR2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"data/lightgbm.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4f38127354bbbf11134e8c14cc17daac7b35e8faaf836cc12d7980bb5480b10"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
